package tests

import (
	"bytes"
	"crypto/md5"
	"database/sql"
	"encoding/hex"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net"
	"os"
	"path/filepath"
	"strings"
	"testing"
	"time"

	"github.com/google/uuid"
	_ "github.com/lib/pq"
	amqp "github.com/rabbitmq/amqp091-go"
)

// æµ‹è¯•é…ç½®
const (
	RabbitMQURL      = "amqp://guest:guest@localhost:5672/"
	UploadQueueName  = "file.upload"
	TestFileName     = "test_upload.txt"
	TestFileContent  = "Hello, this is a test file for distributed storage system!\nLine 2\nLine 3\n"
	PostgresNode0DSN = "host=localhost port=20000 user=postgres dbname=driver sslmode=disable"
	PostgresNode1DSN = "host=localhost port=20001 user=postgres dbname=driver sslmode=disable"
	PostgresNode2DSN = "host=localhost port=20002 user=postgres dbname=driver sslmode=disable"
	PostgresNode3DSN = "host=localhost port=20003 user=postgres dbname=driver sslmode=disable"
	PostgresNode4DSN = "host=localhost port=20004 user=postgres dbname=driver sslmode=disable"
)

// ä¸Šä¼ å…ƒæ•°æ®è¯·æ±‚ç»“æ„
type UploadMetaDataArgs struct {
	Operation string `json:"operation"`
	FileName  string `json:"file_name"`
	FileSize  int64  `json:"file_size"`
}

// ä¸Šä¼ å…ƒæ•°æ®å“åº”ç»“æ„
type UploadMetaDataReply struct {
	OK         bool   `json:"ok"`
	Err        string `json:"err,omitempty"`
	UploadAddr string `json:"upload_addr"`
	Token      string `json:"token"`
}

// TestFileUploadIntegration æ–‡ä»¶ä¸Šä¼ é›†æˆæµ‹è¯•
// å‰ç½®æ¡ä»¶ï¼šéœ€è¦å…ˆå¯åŠ¨ Docker é›†ç¾¤
// è¿è¡Œå‘½ä»¤ï¼š.\scripts\start_docker_cluster.ps1
func TestFileUploadIntegration(t *testing.T) {
	t.Log("=== æ–‡ä»¶ä¸Šä¼ é›†æˆæµ‹è¯• ===")

	// æ­¥éª¤1ï¼šæ£€æŸ¥ Docker é›†ç¾¤çŠ¶æ€
	t.Log("\n[æ­¥éª¤1] æ£€æŸ¥ Docker é›†ç¾¤çŠ¶æ€...")
	if err := checkDockerCluster(t); err != nil {
		t.Fatalf("Docker é›†ç¾¤æœªå°±ç»ª: %v\nè¯·å…ˆè¿è¡Œ: .\\scripts\\start_docker_cluster.ps1", err)
	}
	t.Log("âœ“ Docker é›†ç¾¤è¿è¡Œæ­£å¸¸")

	// æ­¥éª¤2ï¼šåˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„
	t.Log("\n[æ­¥éª¤2] åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„...")
	if err := initDatabaseSchema(t); err != nil {
		t.Fatalf("æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: %v", err)
	}
	t.Log("âœ“ æ•°æ®åº“è¡¨ç»“æ„å·²åˆ›å»º")

	// æ­¥éª¤3ï¼šåˆ›å»ºæµ‹è¯•æ–‡ä»¶
	t.Log("\n[æ­¥éª¤3] åˆ›å»ºæµ‹è¯•æ–‡ä»¶...")
	testFile := createTestFile(t)
	defer os.Remove(testFile)
	t.Logf("âœ“ æµ‹è¯•æ–‡ä»¶å·²åˆ›å»º: %s (å¤§å°: %d å­—èŠ‚)", testFile, len(TestFileContent))

	// æ­¥éª¤4ï¼šè¿æ¥ RabbitMQ å¹¶è¯·æ±‚ä¸Šä¼ 
	t.Log("\n[æ­¥éª¤4] è¿æ¥ RabbitMQ å¹¶è¯·æ±‚ä¸Šä¼ åœ°å€...")
	uploadReply, err := requestUploadAddress(t, testFile)
	if err != nil {
		t.Fatalf("è¯·æ±‚ä¸Šä¼ åœ°å€å¤±è´¥: %v", err)
	}
	t.Logf("âœ“ è·å¾—ä¸Šä¼ åœ°å€: %s, Token: %s", uploadReply.UploadAddr, uploadReply.Token)

	// æ­¥éª¤5ï¼šé€šè¿‡ TCP ä¸Šä¼ æ–‡ä»¶
	t.Log("\n[æ­¥éª¤5] é€šè¿‡ TCP ä¸Šä¼ æ–‡ä»¶...")
	if err := uploadFileViaTCP(t, testFile, uploadReply.UploadAddr, uploadReply.Token); err != nil {
		t.Fatalf("æ–‡ä»¶ä¸Šä¼ å¤±è´¥: %v", err)
	}
	t.Log("âœ“ æ–‡ä»¶ä¸Šä¼ æˆåŠŸ")

	// æ­¥éª¤6ï¼šç­‰å¾…æ–‡ä»¶å¤åˆ¶å®Œæˆ
	t.Log("\n[æ­¥éª¤6] ç­‰å¾…æ–‡ä»¶å¤åˆ¶åˆ°å…¶ä»–èŠ‚ç‚¹...")
	time.Sleep(5 * time.Second)
	t.Log("âœ“ ç­‰å¾…å®Œæˆ")

	// æ­¥éª¤7ï¼šéªŒè¯æ•°æ®åº“è®°å½•
	t.Log("\n[æ­¥éª¤7] éªŒè¯æ•°æ®åº“è®°å½•...")
	fileInfo, err := verifyDatabaseRecord(t, TestFileName)
	if err != nil {
		t.Fatalf("æ•°æ®åº“éªŒè¯å¤±è´¥: %v", err)
	}
	t.Logf("âœ“ æ•°æ®åº“è®°å½•æ­£ç¡®:")
	t.Logf("  - æ–‡ä»¶ID: %d", fileInfo.ID)
	t.Logf("  - æ–‡ä»¶å: %s", fileInfo.FileName)
	t.Logf("  - æ–‡ä»¶å¤§å°: %d å­—èŠ‚", fileInfo.FileSize)
	t.Logf("  - å­˜å‚¨èŠ‚ç‚¹: %s", fileInfo.StorageNodes)

	// æ­¥éª¤8ï¼šéªŒè¯æ–‡ä»¶å†…å®¹å®Œæ•´æ€§
	t.Log("\n[æ­¥éª¤8] éªŒè¯æ–‡ä»¶å†…å®¹å®Œæ•´æ€§...")
	if err := verifyFileIntegrity(t, fileInfo); err != nil {
		t.Fatalf("æ–‡ä»¶å®Œæ•´æ€§éªŒè¯å¤±è´¥: %v", err)
	}
	t.Log("âœ“ æ–‡ä»¶å†…å®¹å®Œæ•´ï¼ŒMD5æ ¡éªŒé€šè¿‡")

	// æ­¥éª¤9ï¼šç»Ÿè®¡æµ‹è¯•ç»“æœ
	t.Log("\n=== æµ‹è¯•ç»“æœæ±‡æ€» ===")
	t.Logf("âœ“ æ–‡ä»¶ä¸Šä¼ æˆåŠŸ")
	t.Logf("âœ“ æ–‡ä»¶å·²å¤åˆ¶åˆ° %d ä¸ªèŠ‚ç‚¹", len(splitStorageNodes(fileInfo.StorageNodes)))
	t.Logf("âœ“ æ•°æ®åº“è®°å½•æ­£ç¡®")
	t.Logf("âœ“ æ–‡ä»¶å†…å®¹å®Œæ•´")
	t.Log("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
}

// checkDockerCluster æ£€æŸ¥ Docker é›†ç¾¤æ˜¯å¦è¿è¡Œ
func checkDockerCluster(t *testing.T) error {
	// æ£€æŸ¥ RabbitMQ
	conn, err := amqp.Dial(RabbitMQURL)
	if err != nil {
		return fmt.Errorf("æ— æ³•è¿æ¥åˆ° RabbitMQ: %w", err)
	}
	conn.Close()

	// æ£€æŸ¥ PostgreSQL (è‡³å°‘ä¸€ä¸ªèŠ‚ç‚¹)
	db, err := sql.Open("postgres", PostgresNode0DSN)
	if err != nil {
		return fmt.Errorf("æ— æ³•è¿æ¥åˆ° PostgreSQL: %w", err)
	}
	defer db.Close()

	if err := db.Ping(); err != nil {
		return fmt.Errorf("PostgreSQL ä¸å¯ç”¨: %w", err)
	}

	return nil
}

// initDatabaseSchema åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„
func initDatabaseSchema(t *testing.T) error {
	// è¿æ¥åˆ°æ‰€æœ‰ PostgreSQL èŠ‚ç‚¹å¹¶åˆ›å»ºè¡¨
	dsns := []string{
		PostgresNode0DSN,
		PostgresNode1DSN,
		PostgresNode2DSN,
		PostgresNode3DSN,
		PostgresNode4DSN,
	}

	for i, dsn := range dsns {
		db, err := sql.Open("postgres", dsn)
		if err != nil {
			return fmt.Errorf("è¿æ¥èŠ‚ç‚¹%då¤±è´¥: %w", i, err)
		}
		defer db.Close()

		// åˆ›å»º files è¡¨
		_, err = db.Exec(`
			CREATE TABLE IF NOT EXISTS files (
				id BIGSERIAL PRIMARY KEY,
				file_name VARCHAR(255) NOT NULL,
				file_size BIGINT NOT NULL,
				local_path VARCHAR(500),
				storage_nodes TEXT,
				storage_add VARCHAR(500),
				owner_id VARCHAR(100),
				created_at TIMESTAMP NOT NULL DEFAULT NOW(),
				updated_at TIMESTAMP DEFAULT NOW()
			)
		`)
		if err != nil {
			return fmt.Errorf("åˆ›å»ºfilesè¡¨å¤±è´¥(èŠ‚ç‚¹%d): %w", i, err)
		}

		// æ¸…ç†æ—§çš„æµ‹è¯•æ•°æ®
		_, err = db.Exec("DELETE FROM files WHERE file_name = $1", TestFileName)
		if err != nil {
			t.Logf("è­¦å‘Š: æ¸…ç†æ—§æ•°æ®å¤±è´¥(èŠ‚ç‚¹%d): %v", i, err)
		}
	}

	return nil
}

// createTestFile åˆ›å»ºæµ‹è¯•æ–‡ä»¶
func createTestFile(t *testing.T) string {
	tmpFile := filepath.Join(os.TempDir(), TestFileName)
	if err := os.WriteFile(tmpFile, []byte(TestFileContent), 0644); err != nil {
		t.Fatalf("åˆ›å»ºæµ‹è¯•æ–‡ä»¶å¤±è´¥: %v", err)
	}
	return tmpFile
}

// requestUploadAddress é€šè¿‡ RabbitMQ è¯·æ±‚ä¸Šä¼ åœ°å€
func requestUploadAddress(t *testing.T, filePath string) (*UploadMetaDataReply, error) {
	// è¿æ¥ RabbitMQ
	conn, err := amqp.Dial(RabbitMQURL)
	if err != nil {
		return nil, fmt.Errorf("è¿æ¥ RabbitMQ å¤±è´¥: %w", err)
	}
	defer conn.Close()

	ch, err := conn.Channel()
	if err != nil {
		return nil, fmt.Errorf("åˆ›å»ºé€šé“å¤±è´¥: %w", err)
	}
	defer ch.Close()

	// å£°æ˜è¯·æ±‚é˜Ÿåˆ—
	_, err = ch.QueueDeclare(UploadQueueName, true, false, false, false, nil)
	if err != nil {
		return nil, fmt.Errorf("å£°æ˜é˜Ÿåˆ—å¤±è´¥: %w", err)
	}

	// åˆ›å»ºå›å¤é˜Ÿåˆ—
	replyQ, err := ch.QueueDeclare("", false, true, true, false, nil)
	if err != nil {
		return nil, fmt.Errorf("åˆ›å»ºå›å¤é˜Ÿåˆ—å¤±è´¥: %w", err)
	}

	// æ¶ˆè´¹å›å¤é˜Ÿåˆ—
	msgs, err := ch.Consume(replyQ.Name, "", true, true, false, false, nil)
	if err != nil {
		return nil, fmt.Errorf("æ¶ˆè´¹å›å¤é˜Ÿåˆ—å¤±è´¥: %w", err)
	}

	// è·å–æ–‡ä»¶ä¿¡æ¯
	fileInfo, err := os.Stat(filePath)
	if err != nil {
		return nil, fmt.Errorf("è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥: %w", err)
	}

	// æ„é€ ä¸Šä¼ è¯·æ±‚
	req := UploadMetaDataArgs{
		Operation: "upload_file",
		FileName:  filepath.Base(filePath),
		FileSize:  fileInfo.Size(),
	}

	body, err := json.Marshal(req)
	if err != nil {
		return nil, fmt.Errorf("åºåˆ—åŒ–è¯·æ±‚å¤±è´¥: %w", err)
	}

	corrID := uuid.NewString()

	// å‘é€è¯·æ±‚
	err = ch.Publish("", UploadQueueName, false, false, amqp.Publishing{
		ContentType:   "application/json",
		Body:          body,
		ReplyTo:       replyQ.Name,
		CorrelationId: corrID,
	})
	if err != nil {
		return nil, fmt.Errorf("å‘é€è¯·æ±‚å¤±è´¥: %w", err)
	}

	// ç­‰å¾…å“åº”
	timeout := time.NewTimer(10 * time.Second)
	defer timeout.Stop()

	for {
		select {
		case d := <-msgs:
			if d.CorrelationId != corrID {
				continue
			}

			var reply UploadMetaDataReply
			if err := json.Unmarshal(d.Body, &reply); err != nil {
				return nil, fmt.Errorf("è§£æå“åº”å¤±è´¥: %w", err)
			}

			if !reply.OK {
				return nil, fmt.Errorf("æœåŠ¡å™¨æ‹’ç»ä¸Šä¼ : %s", reply.Err)
			}

			return &reply, nil

		case <-timeout.C:
			return nil, fmt.Errorf("ç­‰å¾…å“åº”è¶…æ—¶")
		}
	}
}

// uploadFileViaTCP é€šè¿‡ TCP ä¸Šä¼ æ–‡ä»¶
func uploadFileViaTCP(t *testing.T, filePath, addr, token string) error {
	// å¦‚æœåœ°å€æ˜¯ Docker å†…éƒ¨ IP (172.x.x.x æˆ– 192.168.x.x)ï¼Œæ›¿æ¢ä¸º localhost
	if strings.HasPrefix(addr, "172.") || strings.HasPrefix(addr, "192.168.") {
		if _, port, err := net.SplitHostPort(addr); err == nil {
			addr = "localhost:" + port
			t.Logf("  å°† Docker å†…éƒ¨åœ°å€è½¬æ¢ä¸º: %s", addr)
		}
	}

	// è¿æ¥åˆ°ä¸Šä¼ åœ°å€
	conn, err := net.DialTimeout("tcp", addr, 10*time.Second)
	if err != nil {
		return fmt.Errorf("è¿æ¥å¤±è´¥: %w", err)
	}
	defer conn.Close()

	// è®¾ç½®å†™è¶…æ—¶
	conn.SetWriteDeadline(time.Now().Add(30 * time.Second))

	// å‘é€ token
	if _, err := conn.Write([]byte(token + "\n")); err != nil {
		return fmt.Errorf("å‘é€ token å¤±è´¥: %w", err)
	}

	// æ‰“å¼€æ–‡ä»¶
	file, err := os.Open(filePath)
	if err != nil {
		return fmt.Errorf("æ‰“å¼€æ–‡ä»¶å¤±è´¥: %w", err)
	}
	defer file.Close()

	// è·å–æ–‡ä»¶å¤§å°ä»¥éªŒè¯
	fileInfo, err := file.Stat()
	if err != nil {
		return fmt.Errorf("è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥: %w", err)
	}
	expectedSize := fileInfo.Size()

	// å‘é€æ–‡ä»¶å†…å®¹
	sent, err := io.Copy(conn, file)
	if err != nil {
		return fmt.Errorf("å‘é€æ–‡ä»¶å†…å®¹å¤±è´¥: %w", err)
	}

	// éªŒè¯å‘é€çš„å­—èŠ‚æ•°
	if sent != expectedSize {
		return fmt.Errorf("å‘é€ä¸å®Œæ•´: æœŸæœ›=%d, å®é™…=%d", expectedSize, sent)
	}

	t.Logf("  å·²å‘é€ %d å­—èŠ‚", sent)
	return nil
}

// FileInfo æ–‡ä»¶ä¿¡æ¯ç»“æ„
type FileInfo struct {
	ID           int64
	FileName     string
	FileSize     int64
	LocalPath    string
	StorageNodes string
	StorageAdd   string
	OwnerID      string
	CreatedAt    time.Time
}

// verifyDatabaseRecord éªŒè¯æ•°æ®åº“è®°å½•ï¼ˆæŸ¥è¯¢æ‰€æœ‰èŠ‚ç‚¹ï¼‰
func verifyDatabaseRecord(t *testing.T, fileName string) (*FileInfo, error) {
	return verifyDatabaseRecordWithSize(t, fileName, int64(len(TestFileContent)))
}

func verifyDatabaseRecordWithSize(t *testing.T, fileName string, expectedSize int64) (*FileInfo, error) {
	// å°è¯•æ‰€æœ‰æ•°æ®åº“èŠ‚ç‚¹
	dsns := []string{
		PostgresNode0DSN,
		PostgresNode1DSN,
		PostgresNode2DSN,
		PostgresNode3DSN,
		PostgresNode4DSN,
	}

	// ç­‰å¾…æ•°æ®å†™å…¥ï¼Œè½®è¯¢æ‰€æœ‰èŠ‚ç‚¹
	var fileInfo FileInfo
	var found bool

	for i := 0; i < 10; i++ {
		for nodeIdx, dsn := range dsns {
			db, err := sql.Open("postgres", dsn)
			if err != nil {
				t.Logf("  è­¦å‘Š: è¿æ¥èŠ‚ç‚¹%då¤±è´¥: %v", nodeIdx, err)
				continue
			}

			err = db.QueryRow(`
				SELECT id, file_name, file_size, local_path, 
				       COALESCE(storage_nodes, ''), COALESCE(storage_add, ''), 
				       COALESCE(owner_id, ''), created_at
				FROM files 
				WHERE file_name = $1
				ORDER BY created_at DESC
				LIMIT 1
			`, fileName).Scan(
				&fileInfo.ID,
				&fileInfo.FileName,
				&fileInfo.FileSize,
				&fileInfo.LocalPath,
				&fileInfo.StorageNodes,
				&fileInfo.StorageAdd,
				&fileInfo.OwnerID,
				&fileInfo.CreatedAt,
			)

			db.Close()

			if err == nil {
				found = true
				t.Logf("  åœ¨èŠ‚ç‚¹%dæ‰¾åˆ°æ–‡ä»¶è®°å½•", nodeIdx)
				break
			}

			if err != sql.ErrNoRows {
				t.Logf("  è­¦å‘Š: èŠ‚ç‚¹%dæŸ¥è¯¢å¤±è´¥: %v", nodeIdx, err)
			}
		}

		if found {
			break
		}

		time.Sleep(500 * time.Millisecond)
	}

	if !found {
		return nil, fmt.Errorf("æœªæ‰¾åˆ°æ–‡ä»¶è®°å½•: %s", fileName)
	}

	// éªŒè¯åŸºæœ¬ä¿¡æ¯
	if fileInfo.FileSize != expectedSize {
		return nil, fmt.Errorf("æ–‡ä»¶å¤§å°ä¸åŒ¹é…: æœŸæœ›=%d, å®é™…=%d",
			expectedSize, fileInfo.FileSize)
	}

	// éªŒè¯å­˜å‚¨èŠ‚ç‚¹
	if fileInfo.StorageNodes == "" {
		return nil, fmt.Errorf("storage_nodes ä¸ºç©º")
	}

	nodes := splitStorageNodes(fileInfo.StorageNodes)
	if len(nodes) < 1 {
		return nil, fmt.Errorf("å­˜å‚¨èŠ‚ç‚¹æ•°é‡ä¸è¶³: %d", len(nodes))
	}

	t.Logf("  å­˜å‚¨èŠ‚ç‚¹åˆ—è¡¨: %v", nodes)

	return &fileInfo, nil
}

// verifyFileIntegrity éªŒè¯æ–‡ä»¶å†…å®¹å®Œæ•´æ€§
func verifyFileIntegrity(t *testing.T, fileInfo *FileInfo) error {
	// è®¡ç®—åŸå§‹æ–‡ä»¶çš„ MD5
	expectedMD5 := calculateMD5([]byte(TestFileContent))

	// æ³¨æ„ï¼šåœ¨ Docker ç¯å¢ƒä¸­ï¼Œæ–‡ä»¶å­˜å‚¨åœ¨å®¹å™¨å†…éƒ¨
	// è¿™é‡Œæˆ‘ä»¬åªéªŒè¯æ•°æ®åº“è®°å½•çš„æ­£ç¡®æ€§
	// å®é™…çš„æ–‡ä»¶å†…å®¹éªŒè¯éœ€è¦è¿›å…¥å®¹å™¨æˆ–é€šè¿‡ä¸‹è½½æ¥å£

	t.Logf("  åŸå§‹æ–‡ä»¶ MD5: %s", expectedMD5)
	t.Logf("  æ–‡ä»¶å¤§å°åŒ¹é…: %d å­—èŠ‚", fileInfo.FileSize)

	// éªŒè¯æ–‡ä»¶å¤§å°
	if fileInfo.FileSize != int64(len(TestFileContent)) {
		return fmt.Errorf("æ–‡ä»¶å¤§å°ä¸åŒ¹é…")
	}

	return nil
}

// splitStorageNodes åˆ†å‰²å­˜å‚¨èŠ‚ç‚¹å­—ç¬¦ä¸²
func splitStorageNodes(nodes string) []string {
	if nodes == "" {
		return []string{}
	}
	result := []string{}
	for _, node := range bytes.Split([]byte(nodes), []byte(",")) {
		nodeStr := string(bytes.TrimSpace(node))
		if nodeStr != "" {
			result = append(result, nodeStr)
		}
	}
	return result
}

// calculateMD5 è®¡ç®— MD5 æ ¡éªŒå’Œ
func calculateMD5(data []byte) string {
	hash := md5.Sum(data)
	return hex.EncodeToString(hash[:])
}

// TestMain æµ‹è¯•å…¥å£ï¼Œæ‰“å°ä½¿ç”¨è¯´æ˜
func TestMain(m *testing.M) {
	log.Println("==============================================")
	log.Println("æ–‡ä»¶ä¸Šä¼ é›†æˆæµ‹è¯•")
	log.Println("==============================================")
	log.Println()
	log.Println("å‰ç½®æ¡ä»¶ï¼š")
	log.Println("1. å¯åŠ¨ Docker é›†ç¾¤ï¼š")
	log.Println("   .\\scripts\\start_docker_cluster.ps1")
	log.Println()
	log.Println("2. ç­‰å¾…é›†ç¾¤å¯åŠ¨ï¼ˆçº¦30ç§’ï¼‰")
	log.Println()
	log.Println("3. è¿è¡Œæµ‹è¯•ï¼š")
	log.Println("   go test -v ./tests -run TestFileUploadIntegration")
	log.Println()
	log.Println("åœæ­¢é›†ç¾¤ï¼š")
	log.Println("   .\\scripts\\stop_docker_cluster.ps1")
	log.Println("==============================================")
	log.Println()

	os.Exit(m.Run())
}
