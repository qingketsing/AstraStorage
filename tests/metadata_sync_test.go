package tests

import (
	"database/sql"
	"log"
	"os"
	"strings"
	"testing"
	"time"

	_ "github.com/lib/pq"
)

// TestMetadataSyncToAllNodes æµ‹è¯•æ–‡ä»¶å…ƒæ•°æ®æ˜¯å¦åŒæ­¥åˆ°æ‰€æœ‰èŠ‚ç‚¹
// éªŒè¯ï¼šæ‰€æœ‰5ä¸ªæ•°æ®åº“èŠ‚ç‚¹éƒ½æœ‰æ–‡ä»¶å…ƒæ•°æ®ï¼Œä½†åªæœ‰2ä¸ªèŠ‚ç‚¹å®é™…å­˜å‚¨æ–‡ä»¶
func TestMetadataSyncToAllNodes(t *testing.T) {
	log.SetOutput(os.Stdout)

	t.Log("=== æ–‡ä»¶å…ƒæ•°æ®åŒæ­¥æµ‹è¯• ===")

	// æ­¥éª¤1: æ£€æŸ¥Dockeré›†ç¾¤çŠ¶æ€
	t.Log("\n[æ­¥éª¤1] æ£€æŸ¥ Docker é›†ç¾¤çŠ¶æ€...")
	if err := checkDockerCluster(t); err != nil {
		t.Fatalf("Docker é›†ç¾¤æœªå°±ç»ª: %v\nè¯·å…ˆè¿è¡Œ: .\\scripts\\start_docker_cluster.ps1", err)
	}
	t.Log("âœ“ Docker é›†ç¾¤è¿è¡Œæ­£å¸¸")

	// æ­¥éª¤2: åˆå§‹åŒ–æ•°æ®åº“è¡¨
	t.Log("\n[æ­¥éª¤2] åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„...")
	if err := initDatabaseSchema(t); err != nil {
		t.Fatalf("æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: %v", err)
	}
	t.Log("âœ“ æ•°æ®åº“è¡¨ç»“æ„å·²åˆ›å»º")

	// æ­¥éª¤3: åˆ›å»ºæµ‹è¯•æ–‡ä»¶
	t.Log("\n[æ­¥éª¤3] åˆ›å»ºæµ‹è¯•æ–‡ä»¶...")
	testFile := createTestFile(t)
	defer os.Remove(testFile)
	t.Logf("âœ“ æµ‹è¯•æ–‡ä»¶å·²åˆ›å»º: %s (å¤§å°: %d å­—èŠ‚)", testFile, len(TestFileContent))

	// æ­¥éª¤4: é€šè¿‡RabbitMQè¯·æ±‚ä¸Šä¼ åœ°å€
	t.Log("\n[æ­¥éª¤4] è¿æ¥ RabbitMQ å¹¶è¯·æ±‚ä¸Šä¼ åœ°å€...")
	uploadReply, err := requestUploadAddress(t, testFile)
	if err != nil {
		t.Fatalf("è¯·æ±‚ä¸Šä¼ åœ°å€å¤±è´¥: %v", err)
	}
	t.Logf("âœ“ è·å¾—ä¸Šä¼ åœ°å€: %s, Token: %s", uploadReply.UploadAddr, uploadReply.Token)

	// æ­¥éª¤5: ä¸Šä¼ æ–‡ä»¶
	t.Log("\n[æ­¥éª¤5] é€šè¿‡ TCP ä¸Šä¼ æ–‡ä»¶...")
	if err := uploadFileViaTCP(t, testFile, uploadReply.UploadAddr, uploadReply.Token); err != nil {
		t.Fatalf("æ–‡ä»¶ä¸Šä¼ å¤±è´¥: %v", err)
	}
	t.Log("âœ“ æ–‡ä»¶ä¸Šä¼ æˆåŠŸ")

	// æ­¥éª¤6: ç­‰å¾…æ–‡ä»¶å¤åˆ¶å’Œå…ƒæ•°æ®åŒæ­¥
	t.Log("\n[æ­¥éª¤6] ç­‰å¾…æ–‡ä»¶å¤åˆ¶å’Œå…ƒæ•°æ®åŒæ­¥...")
	time.Sleep(5 * time.Second)
	t.Log("âœ“ ç­‰å¾…å®Œæˆ")

	// æ­¥éª¤7: éªŒè¯æ‰€æœ‰æ•°æ®åº“èŠ‚ç‚¹éƒ½æœ‰å…ƒæ•°æ®è®°å½•
	t.Log("\n[æ­¥éª¤7] éªŒè¯æ‰€æœ‰5ä¸ªæ•°æ®åº“èŠ‚ç‚¹çš„å…ƒæ•°æ®...")
	storageNodes, results := verifyAllDatabasesHaveMetadata(t, TestFileName)

	// æ­¥éª¤8: è¾“å‡ºç»“æœ
	t.Log("\n=== æµ‹è¯•ç»“æœæ±‡æ€» ===")
	t.Log("âœ“ æ–‡ä»¶ä¸Šä¼ æˆåŠŸ")
	t.Logf("âœ“ æ–‡ä»¶å®é™…å­˜å‚¨åœ¨ %d ä¸ªèŠ‚ç‚¹: %v", len(storageNodes), storageNodes)
	t.Logf("âœ“ æ‰€æœ‰ 5 ä¸ªæ•°æ®åº“èŠ‚ç‚¹éƒ½æœ‰å…ƒæ•°æ®è®°å½•")

	nodesWithFile := 0
	nodesWithMetadataOnly := 0
	for i, result := range results {
		if result.HasFile {
			nodesWithFile++
			t.Logf("  - Node %d (port %d): æœ‰å…ƒæ•°æ® ä¸” å­˜å‚¨æ–‡ä»¶ (local_path='%s') âœ“",
				i, 20000+i, result.LocalPath)
		} else {
			nodesWithMetadataOnly++
			t.Logf("  - Node %d (port %d): æœ‰å…ƒæ•°æ® ä½† ä¸å­˜å‚¨æ–‡ä»¶ (local_path='') âœ“", i, 20000+i)
		}
	}

	t.Logf("âœ“ ç»Ÿè®¡: %dä¸ªèŠ‚ç‚¹å­˜å‚¨æ–‡ä»¶, %dä¸ªèŠ‚ç‚¹åªæœ‰å…ƒæ•°æ®", nodesWithFile, nodesWithMetadataOnly)

	// éªŒè¯é¢„æœŸï¼šåº”è¯¥æœ‰2ä¸ªèŠ‚ç‚¹å­˜å‚¨æ–‡ä»¶ï¼Œ3ä¸ªèŠ‚ç‚¹åªæœ‰å…ƒæ•°æ®
	if nodesWithFile != 2 {
		t.Errorf("âŒ é”™è¯¯: é¢„æœŸ2ä¸ªèŠ‚ç‚¹å­˜å‚¨æ–‡ä»¶ï¼Œå®é™…%dä¸ª", nodesWithFile)
	}
	if nodesWithMetadataOnly != 3 {
		t.Errorf("âŒ é”™è¯¯: é¢„æœŸ3ä¸ªèŠ‚ç‚¹åªæœ‰å…ƒæ•°æ®ï¼Œå®é™…%dä¸ª", nodesWithMetadataOnly)
	}

	t.Log("âœ“ å…ƒæ•°æ®åŒæ­¥æ­£ç¡®")
	t.Log("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
}

// MetadataResult è¡¨ç¤ºæ¯ä¸ªèŠ‚ç‚¹çš„å…ƒæ•°æ®çŠ¶æ€
type MetadataResult struct {
	NodeIndex    int
	Port         int
	HasMetadata  bool
	HasFile      bool // local_path ä¸ä¸ºç©ºè¡¨ç¤ºæœ‰æ–‡ä»¶
	LocalPath    string
	FileName     string
	FileSize     int64
	StorageNodes string
}

// verifyAllDatabasesHaveMetadata éªŒè¯æ‰€æœ‰5ä¸ªæ•°æ®åº“èŠ‚ç‚¹éƒ½æœ‰å…ƒæ•°æ®
func verifyAllDatabasesHaveMetadata(t *testing.T, fileName string) ([]string, []MetadataResult) {
	results := make([]MetadataResult, 5)
	storageNodesSet := make(map[string]bool)
	var storageNodesStr string

	dsns := []string{
		PostgresNode0DSN,
		PostgresNode1DSN,
		PostgresNode2DSN,
		PostgresNode3DSN,
		PostgresNode4DSN,
	}

	for i := 0; i < 5; i++ {
		port := 20000 + i
		result := MetadataResult{
			NodeIndex: i,
			Port:      port,
		}

		// è¿æ¥æ•°æ®åº“
		db, err := sql.Open("postgres", dsns[i])
		if err != nil {
			t.Logf("  âš  è¿æ¥ Node %d (port %d) å¤±è´¥: %v", i, port, err)
			results[i] = result
			continue
		}
		defer db.Close()

		// æŸ¥è¯¢æ–‡ä»¶è®°å½•
		var id int64
		var localPath sql.NullString // ä¿®æ”¹ä¸º NullString ä»¥å¤„ç† NULL å€¼
		var recordFileName string
		var recordFileSize int64
		var recordStorageNodes string

		query := `SELECT id, file_name, file_size, local_path, storage_nodes 
		          FROM files WHERE file_name = $1 ORDER BY id DESC LIMIT 1`
		err = db.QueryRow(query, fileName).Scan(&id, &recordFileName, &recordFileSize, &localPath, &recordStorageNodes)

		if err == sql.ErrNoRows {
			t.Errorf("  âœ— Node %d (port %d): æ²¡æœ‰æ‰¾åˆ°æ–‡ä»¶è®°å½•ï¼", i, port)
			result.HasMetadata = false
		} else if err != nil {
			t.Errorf("  âœ— Node %d (port %d): æŸ¥è¯¢å¤±è´¥: %v", i, port, err)
			result.HasMetadata = false
		} else {
			result.HasMetadata = true
			result.FileName = recordFileName
			result.FileSize = recordFileSize
			result.StorageNodes = recordStorageNodes

			// å¤„ç† NULL å€¼
			if localPath.Valid {
				result.LocalPath = localPath.String
				result.HasFile = (localPath.String != "")
			} else {
				result.LocalPath = ""
				result.HasFile = false
			}

			if storageNodesStr == "" {
				storageNodesStr = recordStorageNodes
			}

			t.Logf("  âœ“ Node %d (port %d): æ‰¾åˆ°è®°å½• (id=%d, local_path='%s', storage_nodes=%s)",
				i, port, id, result.LocalPath, recordStorageNodes)
		}

		results[i] = result
	}

	// æ£€æŸ¥æ˜¯å¦æ‰€æœ‰èŠ‚ç‚¹éƒ½æœ‰å…ƒæ•°æ®
	allHaveMetadata := true
	for _, result := range results {
		if !result.HasMetadata {
			allHaveMetadata = false
			break
		}
	}

	if !allHaveMetadata {
		t.Fatal("âŒ ä¸æ˜¯æ‰€æœ‰èŠ‚ç‚¹éƒ½æœ‰å…ƒæ•°æ®è®°å½•ï¼")
	}

	// è§£æ storage_nodes
	if storageNodesStr != "" {
		nodes := strings.Split(storageNodesStr, ",")
		for _, node := range nodes {
			storageNodesSet[strings.TrimSpace(node)] = true
		}
	}

	storageNodes := make([]string, 0, len(storageNodesSet))
	for node := range storageNodesSet {
		storageNodes = append(storageNodes, node)
	}

	return storageNodes, results
}
